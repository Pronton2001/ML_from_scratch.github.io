{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Why Random Forest?\n",
    "`Decision tree` is susceptible to high variance if it is not pruned. \n",
    "\n",
    "`Bagging` is the combination of many Decision Tree models, and the prediction follows the crowd; but these tree are highly correlated.\n",
    "\n",
    "`Random Forest`, the extension of `Bagging`, constrains the features that can be used to build the trees, forcing trees to be different. This, in turn, can give a lift in performance.\n",
    "\n",
    "`Bagging` and `Random Forest` execute Decision Tree upon a sample with replacement of the training dataset. **Sample with replacement** means that the same row may be chosen and added to samples more than once.\n",
    "\n",
    "Of that training sample, one-third of it is set aside as test data, known as the out-of-bag (`oob`) sample, used for cross-validation, finalizing that prediction.\n",
    "\n",
    "**Key Benefits**\n",
    "- Reduced risk of **overfitting**: Averaging of **uncorrelated trees** lowers the overall **variance** and prediction **error**\n",
    "- Provides flexibility: Handle both **regression** and **classification** tasks with a high degree of accuracy\n",
    "- Easy to determine **feature importance**: Gini importance, mean decrease in impurity (MDI) and permutation importance known as mean decrease accuracy (MDA)\n",
    "\n",
    "**Key Challenges**\n",
    "- Time-consuming process\n",
    "- Requires more resources\n",
    "- More complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "from math import log,sqrt\n",
    "from random import randrange, seed\n",
    "from statistics import mode\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [[2.771244718, 1.784783929, 0],\n",
    "           [1.728571309, 1.169761413, 0.1],\n",
    "           [3.678319846, 2.81281357, 0.2],\n",
    "           [3.961043357, 2.61995032, -0.1],\n",
    "           [2.999208922, 2.209014212, 0.3],\n",
    "           [7.497545867, 3.162953546, 1.1],\n",
    "           [9.00220326, 3.339047188, 1.2],\n",
    "           [7.444542326, 0.476683375, 1.9],\n",
    "           [10.12493903, 3.234550982, 0.9],\n",
    "           [6.642287351, 3.319983761, 1.6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Calculating splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4714045207910317\n",
      "0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "def split_criteria(y, criteria = 'std'):\n",
    "    \"\"\"\n",
    "    split_criteria([1,2,3,4,3], 'std') = std([1,2,3,4,3])\n",
    "    \"\"\"\n",
    "    if criteria == 'std':\n",
    "        if len(y) == 0: return 0\n",
    "        return np.std(y)\n",
    "    if criteria == 'mae':\n",
    "        u = np.mean(y)\n",
    "        return np.mean(np.abs(u - y))\n",
    "\n",
    "group_targets = [[1,2,1],[1,1,2]]\n",
    "s1, s2 = group_targets\n",
    "print(split_criteria(s1, 'std'))\n",
    "print(split_criteria(s1, 'mae'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attribute': 0,\n",
       " 'value': 6.642287351,\n",
       " 'groups': ([[2.771244718, 1.784783929, 0],\n",
       "   [1.728571309, 1.169761413, 0.1],\n",
       "   [3.678319846, 2.81281357, 0.2],\n",
       "   [3.961043357, 2.61995032, -0.1],\n",
       "   [2.999208922, 2.209014212, 0.3]],\n",
       "  [[7.497545867, 3.162953546, 1.1],\n",
       "   [9.00220326, 3.339047188, 1.2],\n",
       "   [7.444542326, 0.476683375, 1.9],\n",
       "   [10.12493903, 3.234550982, 0.9],\n",
       "   [6.642287351, 3.319983761, 1.6]])}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_split(index, value, dataset):\n",
    "    \"\"\"\n",
    "    Split a dataset based on an attribute and an attribute value.\n",
    "    Complexity: O(#rows)\n",
    "    \"\"\"\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "def get_split(dataset, n_features, criteria):\n",
    "    \"\"\"\n",
    "    This heuristic algorithm loops all rows (samples) and column (attributes), thus it is painful for computing.\n",
    "    Complexity: O(#rows^2 x #columns) x O(gini_index)\n",
    "    \"\"\"\n",
    "    attributes = len(dataset[0]) - 1\n",
    "    retAttribute, retValue, retGroups, min_loss = None, None, None, 999\n",
    "\n",
    "    features = list()\n",
    "    counter = 0\n",
    "    while counter < n_features:\n",
    "        index = randrange(len(dataset[0])-1)\n",
    "        if index not in features:\n",
    "            counter = counter + 1\n",
    "            features.append(index)\n",
    "    for row in dataset:\n",
    "        for attribute in features:\n",
    "            group_left, group_right = test_split(attribute, row[attribute], dataset)\n",
    "#             group_left, group_right = groups\n",
    "            target_left = [row[-1] for row in group_left]\n",
    "            target_right = [row[-1] for row in group_right]\n",
    "\n",
    "            total = len(target_left) + len(target_right)\n",
    "            pL = len(target_left) / total\n",
    "            \n",
    "            loss =  pL * split_criteria(target_left, criteria) + (1 - pL) * split_criteria(target_right, criteria)\n",
    "            if loss < min_loss:\n",
    "                min_loss = loss\n",
    "                retAttribute, retValue, retGroups = attribute, row[attribute], (group_left, group_right)\n",
    "    return {'attribute': retAttribute, 'value': retValue, 'groups': retGroups}\n",
    "\n",
    "get_split(dataset, 2, 'std')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_terminal(group):\n",
    "    assert group, 'group should not be empty'\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return np.mean(outcomes)  # mean of predictions\n",
    "\n",
    "def split(node, max_depth, min_size, depth, n_features, criteria):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    # check for a no split\n",
    "    if not left or not right:  # left or right is empty list\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    # check for max depth\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    # process left child\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left, n_features, criteria)\n",
    "        split(node['left'], max_depth, min_size, depth+1, n_features, criteria)\n",
    "    # process right child\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right, n_features, criteria)\n",
    "        split(node['right'], max_depth, min_size, depth+1, n_features, criteria)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Build a tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X2 < 3.163]\n",
      "--[X2 < 1.170]\n",
      "----[1.9]\n",
      "----[X1 < 3.961]\n",
      "------[X1 < 2.999]\n",
      "--------[X2 < 1.785]\n",
      "----------[0.1]\n",
      "----------[0.0]\n",
      "--------[X1 < 3.678]\n",
      "----------[0.3]\n",
      "----------[0.2]\n",
      "------[-0.1]\n",
      "--[X1 < 7.498]\n",
      "----[1.6]\n",
      "----[X2 < 3.339]\n",
      "------[X1 < 10.125]\n",
      "--------[1.1]\n",
      "--------[0.9]\n",
      "------[1.2]\n"
     ]
    }
   ],
   "source": [
    "def build_tree(train_set, max_depth, min_size, n_features, criteria = 'std'):\n",
    "\troot = get_split(train_set, n_features, criteria)\n",
    "\tsplit(root, max_depth, min_size, 0, n_features, criteria)\n",
    "\treturn root\n",
    "\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[X%d < %.3f]' %\n",
    "              ((depth*'-', (node['attribute']+1), node['value'])))\n",
    "        print_tree(node['left'], depth+2)\n",
    "        print_tree(node['right'], depth+2)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*'-', node)))  # This is cool!\n",
    "\n",
    "\n",
    "tree = build_tree(dataset, 6, 1, 1, 'std')\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tree, input_row):  # input is row of testset\n",
    "    if input_row[tree['attribute']] < tree['value']:\n",
    "        if isinstance(tree['left'], dict):\n",
    "            return predict(tree['left'], input_row)\n",
    "        else:\n",
    "            return tree['left']\n",
    "    else:\n",
    "        if isinstance(tree['right'], dict):\n",
    "            return predict(tree['right'], input_row)\n",
    "        else:\n",
    "            return tree['right']\n",
    "\n",
    "# Root Mean Square Error\n",
    "def rmse(y, y_hat):\n",
    "    if not isinstance(y, np.ndarray):\n",
    "        y, y_hat = np.array(y), np.array(y_hat)\n",
    "    return np.mean((y - y_hat)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build a forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08, 0.64, 0.21999999999999997]\n"
     ]
    }
   ],
   "source": [
    "def subsample_idx(data_size, sample_size):\n",
    "    \"\"\"\n",
    "    Retrieve from the `dataset` indices *randomly* with `sample_size`\n",
    "    \"\"\"\n",
    "    sample_indices = list()\n",
    "    counter = 0\n",
    "    while(counter < sample_size):\n",
    "        index = randrange(data_size)\n",
    "        sample_indices.append(index)\n",
    "        counter += 1\n",
    "    return sample_indices\n",
    "\n",
    "def bagging_predict(trees, row):\n",
    "    return np.mean([predict(tree, row) for tree in trees])  # mean of trees' predictions\n",
    "\n",
    "def random_forest_regressor(train_set, test_set, max_depth, min_size, n_features, n_trees, sample_size, criteria):\n",
    "    trees = list()\n",
    "    for i in range(n_trees):\n",
    "        sample_indices = subsample_idx(len(train_set), sample_size)\n",
    "        sample = [train_set[i] for i in sample_indices]\n",
    "        tree = build_tree(sample, max_depth, min_size, n_features, criteria)\n",
    "        trees.append(tree)\n",
    "    predictions = [bagging_predict(trees, row) for row in test_set]\n",
    "    return predictions\n",
    "\n",
    "print(random_forest_regressor(dataset[:int(len(dataset)*7/10)], dataset[int(len(dataset)*7/10):], 5, 1, 1, 5, 4, 'std'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Out-of-bag error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RÂ² score, the coefficient of determination\n",
    "\n",
    "$$R^2(y, \\hat{y}) = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$$\n",
    "\n",
    "Upperbound (1), lowerbound(may be negative - arbitrarily worse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13071.26070115118"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def r2_score(y, y_hat):\n",
    "        y_mean = np.mean(y)\n",
    "        error_sqr = np.sum((y - y_hat)**2) # error square\n",
    "        denom = np.sum((y - y_mean)**2)\n",
    "        R2 = 1 - error_sqr / denom\n",
    "        return R2\n",
    "y = np.array([1,2,99,4,4,5])\n",
    "y_hat = np.array([1,2,3,4,99,-10000])\n",
    "r2_score(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oob_classifier_r2_score(train_set, max_depth, min_size, n_features, n_trees, sample_size, criteria):\n",
    "    X_train = np.array([x[:-1] for x in train_set])\n",
    "    y_train = np.array([x[-1] for x in train_set])\n",
    "    n_samples = len(X_train)\n",
    "\n",
    "    predictions = np.zeros(n_samples)\n",
    "    n_predictions = np.zeros(n_samples)\n",
    "    \n",
    "    for i in range(n_trees):\n",
    "        # Sampling and collect out-of-bag(oob) indices\n",
    "        sample_indices = subsample_idx(len(train_set), sample_size)\n",
    "        oob_indices = np.array([i for i in range(n_samples) if i not in sample_indices])\n",
    "        \n",
    "        # Build a tree\n",
    "        sample = [train_set[i] for i in sample_indices]\n",
    "        tree = build_tree(sample, max_depth, min_size, n_features, criteria)\n",
    "        \n",
    "        # Accumulate prediction value and prediction number over OOB dataset\n",
    "        tree_preds = [predict(tree, X_train[idx]) for idx in oob_indices]\n",
    "        predictions[oob_indices] += tree_preds\n",
    "        n_predictions[oob_indices] +=1\n",
    "\n",
    "        # Check to avoid divide by zero\n",
    "        if (n_predictions == 0).any():\n",
    "            warnings.warn(\"Too few trees; some variables do not have OOB scores.\")\n",
    "            n_predictions[n_predictions == 0] = 1\n",
    "            \n",
    "    predictions /= n_predictions\n",
    "    return r2_score(y_train, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Work with real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    file = open(filename, \"rt\")\n",
    "    lines = reader(file)\n",
    "    dataset = list(lines)\n",
    "    return dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column])\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "\tclass_values = [row[column] for row in dataset]\n",
    "\tunique = set(class_values)\n",
    "\tlookup = dict()\n",
    "\tfor i, value in enumerate(unique):\n",
    "\t\tlookup[value] = i\n",
    "\tfor row in dataset:\n",
    "\t\trow[column] = lookup[row[column]]\n",
    "\treturn lookup\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for i in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args, metric = rmse):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])  # concatenate lists of lists to a list\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            # test_set use to predict => no need to hold [class] data\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last row convert from str to int\n",
      "# trees: 1\n",
      "======> Runned in 3.0230 seconds\n",
      "Root Mean Square Error: 0.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_566/1847774017.py:31: UserWarning: Too few trees; some variables do not have OOB scores.\n",
      "  warnings.warn(\"Too few trees; some variables do not have OOB scores.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======> Runned in 0.6401 seconds\n",
      "OOB_r2_score: -0.493\n",
      "# trees: 5\n",
      "======> Runned in 15.7013 seconds\n",
      "Root Mean Square Error: 0.165\n",
      "======> Runned in 3.4775 seconds\n",
      "OOB_r2_score: -0.032\n",
      "# trees: 10\n",
      "======> Runned in 36.4092 seconds\n",
      "Root Mean Square Error: 0.136\n",
      "======> Runned in 7.6199 seconds\n",
      "OOB_r2_score: 0.307\n"
     ]
    }
   ],
   "source": [
    "seed(1)\n",
    "# load and prepare data\n",
    "filename = 'data/sonar.csv' # 0.017\n",
    "# filename = 'data/BankNote_Authentication.csv' # 0.232\n",
    "dataset = load_csv(filename)\n",
    "# remove the string attributes\n",
    "dataset.pop(0) \n",
    "\n",
    "# convert string attributes to float\n",
    "for i in range(len(dataset[0]) - 1):\n",
    "    str_column_to_float(dataset, i)\n",
    "\n",
    "# Check if the last row is not INT{0,1}\n",
    "if not isinstance(dataset[0][-1], int):\n",
    "    print(\"The last row convert from str to int\")\n",
    "    str_column_to_int(dataset, len(dataset[0])-1)\n",
    "\n",
    "n_folds = 5\n",
    "max_depth = 5\n",
    "min_size = 10\n",
    "n_trees = [1, 5, 10]\n",
    "n_features = round(sqrt(len(dataset[0]) - 1))\n",
    "sample_size = len(dataset)\n",
    "# (train_set, max_depth, min_size, n_features, n_trees, sample_size):\n",
    "for n_tree in n_trees:\n",
    "    print('# trees: %s' % n_tree)\n",
    "    tic = time.perf_counter()\n",
    "    scores = evaluate_algorithm(dataset, random_forest_regressor, n_folds, max_depth, min_size, n_features, n_tree, sample_size, 'std')\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"======> Runned in {toc - tic:0.4f} seconds\")\n",
    "    \n",
    "    print('Root Mean Square Error: %.3f' % (sum(scores)/float(len(scores))))\n",
    "    tic = time.perf_counter()\n",
    "    oob_score = oob_classifier_r2_score(dataset, max_depth, min_size, n_features, n_tree, sample_size, 'std')\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"======> Runned in {toc - tic:0.4f} seconds\")\n",
    "    print('OOB_r2_score: %.3f' % oob_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X, y):\n",
    "    assert len(X) == len(y)\n",
    "    permute = np.random.permutation(len(y))\n",
    "    return X[permute], y[permute]\n",
    "\n",
    "def train_test_split_manual(X, y, test_size=0.3):\n",
    "    nX, ny = shuffle_data(X,y)\n",
    "    split_index = int(len(X)*test_size)\n",
    "    testX = nX[:split_index]\n",
    "    trainX = nX[split_index:]\n",
    "    testy = ny[:split_index]\n",
    "    trainy = ny[split_index:]\n",
    "    return trainX, testX, trainy, testy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_data():\n",
    "    x = np.linspace(-10,10,500)\n",
    "    y = np.sin(x)\n",
    "    return x, y\n",
    "\n",
    "X,y = get_data()\n",
    "\n",
    "plt.plot(X,y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tri-huynh/miniconda3/envs/ml/lib/python3.9/site-packages/numpy/core/fromnumeric.py:3419: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/tri-huynh/miniconda3/envs/ml/lib/python3.9/site-packages/numpy/core/_methods.py:188: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6335/2816330857.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# predictions = decision_tree_regressor(list(zip(x_train, y_train)), \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#                                       list(zip(x_test, y_test)), max_depth, min_size, criteria='mae')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m predictions = random_forest_regressor(list(zip(x_train, y_train)),list(zip(x_test, y_test)), \n\u001b[0m\u001b[1;32m     13\u001b[0m                                       max_depth, min_size, n_features, n_trees, sample_size, criteria='mae')\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# def random_forest_regressor(train_set, test_set, max_depth, min_size, n_features, n_trees, sample_size, criteria):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6335/289662862.py\u001b[0m in \u001b[0;36mrandom_forest_regressor\u001b[0;34m(train_set, test_set, max_depth, min_size, n_features, n_trees, sample_size, criteria)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0msample_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubsample_idx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msample_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtrees\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbagging_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6335/1158776004.py\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(train_set, max_depth, min_size, n_features, criteria)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'std'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m         \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6335/3357191652.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(node, max_depth, min_size, depth, n_features, criteria)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# process right child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6335/3357191652.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(node, max_depth, min_size, depth, n_features, criteria)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# process right child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6335/3357191652.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(node, max_depth, min_size, depth, n_features, criteria)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# process right child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6335/3357191652.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(node, max_depth, min_size, depth, n_features, criteria)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# process right child\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6335/3357191652.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(node, max_depth, min_size, depth, n_features, criteria)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'groups'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;32mdel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'groups'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# check for a no split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "n_trees = 5\n",
    "n_folds = 5\n",
    "max_depth = 20  # maximum depth of tree\n",
    "min_size = 2  # minimum size of 1 group\n",
    "n_features = round(sqrt(len(dataset[0]) - 1))\n",
    "\n",
    "# Draw the predictions on the real data\n",
    "x_train, x_test, y_train, y_test = train_test_split_manual(X,y,test_size=0.3)\n",
    "sample_size = len(x_train)\n",
    "# predictions = decision_tree_regressor(list(zip(x_train, y_train)), \\\n",
    "#                                       list(zip(x_test, y_test)), max_depth, min_size, criteria='mae')\n",
    "predictions = random_forest_regressor(list(zip(x_train, y_train)),list(zip(x_test, y_test)), \n",
    "                                      max_depth, min_size, n_features, n_trees, sample_size, criteria='mae')\n",
    "# def random_forest_regressor(train_set, test_set, max_depth, min_size, n_features, n_trees, sample_size, criteria):\n",
    "plt.scatter(x_test,predictions,c='r', marker='^')\n",
    "plt.plot(X,y);\n",
    "\n",
    "# # evaluate algorithm\n",
    "# scores = evaluate_algorithm(\n",
    "#     list(zip(X,y)), decision_tree_regressor, n_folds, max_depth, min_size, 'std')\n",
    "# print('Scores: %s' % scores)\n",
    "# print('Root Mean Square Error: %.3f' % (sum(scores)/float(len(scores))))\n",
    "\n",
    "\n",
    "# n_trees = [1, 5, 10]\n",
    "# n_features = round(sqrt(len(dataset[0]) - 1))\n",
    "# sample_size = len(dataset)\n",
    "# dataset = list(zip(X,y))\n",
    "# for n_tree in n_trees:\n",
    "#     print('# trees: %s' % n_tree)\n",
    "#     tic = time.perf_counter()\n",
    "#     scores = evaluate_algorithm(dataset, random_forest_regressor, n_folds, max_depth, \n",
    "#                                 min_size, n_features, n_tree, sample_size, 'std')\n",
    "#     toc = time.perf_counter()\n",
    "#     print(f\"======> Runned in {toc - tic:0.4f} seconds\")\n",
    "    \n",
    "#     print('Root Mean Square Error: %.3f' % (sum(scores)/float(len(scores))))\n",
    "#     tic = time.perf_counter()\n",
    "#     oob_score = oob_classifier_r2_score(dataset, max_depth, min_size, n_features, \n",
    "#                                         n_tree, sample_size, 'std')\n",
    "#     toc = time.perf_counter()\n",
    "#     print(f\"======> Runned in {toc - tic:0.4f} seconds\")\n",
    "#     print('OOB_r2_score: %.3f' % oob_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "Version 0.1: 20/09/2021\n",
    "* Add Out-of-bag(**oob**) error utilizing unsample data for cross-validation (NOT **k cross-validation**), this test is particularly used in `Random Forest` algorithms.\n",
    "* This OOB_score using **r2_score** function provide the indication of goodness of fit. Best possible score is 1.0, it can be negative (arbitrarily worse)\n",
    "* OOB_r2_score:\n",
    "    - -0.493 data/sonar.csv (1 tree)\n",
    "    - -0.032 data/sonar.csv (5 trees)\n",
    "    - 0.307 data/sonar.csv (10 trees)\n",
    "* RMSE:\n",
    "    - 0.300 data/sonar.csv (1 tree)\n",
    "    - 0.165 data/sonar.csv (5 trees)\n",
    "    - 0.136 data/sonar.csv (10 trees)\n",
    "    \n",
    "`Question`: Why the running time of RF regressor is very slow compared to that of RF classifier (x4)?\n",
    "    - Compute std, mae\n",
    "    - \n",
    "    - Compute R2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Refs\n",
    "https://machinelearningmastery.com/implement-random-forest-scratch-python/\n",
    "\n",
    "https://www.ibm.com/cloud/learn/random-forest\n",
    "\n",
    "https://github.com/parrt/random-forest-importances/blob/master/src/rfpimp.py"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "28f96ec01d3331ab2b5d4a1bb32d02e762004829634cea2cd2eeaefdb8bb653c"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
